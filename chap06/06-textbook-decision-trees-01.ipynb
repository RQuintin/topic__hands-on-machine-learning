{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 6 -  Decision Trees\n",
    "\n",
    "### Training and Visualising a Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T08:46:23.096936Z",
     "start_time": "2020-04-16T08:46:22.108837Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from graphviz import Source # For creating the visualisation of the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T08:46:23.110418Z",
     "start_time": "2020-04-16T08:46:23.099000Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ingest\n",
    "iris_dataset = datasets.load_iris()\n",
    "X = pd.DataFrame(iris_dataset['data'], columns=iris_dataset['feature_names'])\n",
    "y = pd.Series(iris_dataset['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T08:46:23.130252Z",
     "start_time": "2020-04-16T08:46:23.114484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X.iloc[:,2:], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T08:46:23.138892Z",
     "start_time": "2020-04-16T08:46:23.133788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T08:46:23.232782Z",
     "start_time": "2020-04-16T08:46:23.141636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Source.gv.pdf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualise tree\n",
    "graph = Source(export_graphviz(tree_clf, out_file=None, \n",
    "                               feature_names=iris_dataset['feature_names'][2:], class_names=iris_dataset['target_names']))\n",
    "graph.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the tree, suppose there is a new flower and you want to classify it. Start from the root node. The node checks of the petal length is smaller than 2.45cm. If this is True then move left to the child node. This is a leaf node and the prediction is Setosa. \n",
    "\n",
    "If another flower has a petal length greater than 2.45cm, then move to the right. This child node is not a leaf node so further ask if the petal width is smaller than 1.75cm. If it is then move left to the leaf node. It is a Versicolor. If not then move to the right leaf node. It is a Virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class purity can be measured by Gini impurity or Entropy. Gini impurity is calculated as:\n",
    "$$G_i = 1-\\sum_{k=1}^np_{i,k}^2$$\n",
    "where $p_{i,k}$ is the ratio of class $k$ instances among all the training instances in the node $i$.\n",
    "\n",
    "For a pure node with $[50,0,0]$ members from each class, the Gini score is $1-\\begin{pmatrix}\\frac{0}{50}\\end{pmatrix}^2-\\begin{pmatrix}\\frac{0}{50}\\end{pmatrix}^2-\\begin{pmatrix}\\frac{50}{50}\\end{pmatrix}^2= 0$ \n",
    "\n",
    "For a node of $54$ with $[0,49,5]$ members from each class, the Gini score is $1-\\begin{pmatrix}\\frac{0}\n",
    "{54}\\end{pmatrix}^2-\\begin{pmatrix}\\frac{49}{54}\\end{pmatrix}^2-\\begin{pmatrix}\\frac{5}{54}\\end{pmatrix}^2= 0.168$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is Entropy. It is calculated as \n",
    "$$H_i = -\\sum_{k=1, p_{i,k}\\neq 0}^n p_{i,k}\\log p_{i,k}$$\n",
    "\n",
    "$p_{i,k}\\neq 0$ means to omit all classes $k$ in the node $i$ with no instances.\n",
    "\n",
    "For a pure node with $[50,0,0]$ members from each class, the Entropy calculation is $-\\frac{50}{50} \\log\\begin{pmatrix}\\frac{50}{50}\\end{pmatrix}^2= 0$ \n",
    "\n",
    "For a node of $54$ with $[0,49,5]$ members from each class, the Gini score is $-\\begin{pmatrix}\\frac{49}{54}\\end{pmatrix}\\log\\begin{pmatrix}\\frac{49}{54}\\end{pmatrix}-\\begin{pmatrix}\\frac{5}{54}\\end{pmatrix}\\log\\begin{pmatrix}\\frac{5}{54}\\end{pmatrix}= 0.308$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T08:46:23.249050Z",
     "start_time": "2020-04-16T08:46:23.236583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.1680384087791495\n"
     ]
    }
   ],
   "source": [
    "#Gini Calculations\n",
    "print(1-(0/50)**2-(0/50)**2-(50/50)**2)\n",
    "print(1-(0/54)**2-(49/54)**2-(5/54)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T08:46:23.264326Z",
     "start_time": "2020-04-16T08:46:23.254845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n",
      "0.30849545083110386\n"
     ]
    }
   ],
   "source": [
    "#Entropy Calculations\n",
    "print(-(50/50)*np.log(50/50))\n",
    "print(-(49/54)*np.log(49/54)-(5/54)*np.log(5/54))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Class Probabilities\n",
    "\n",
    "A decision tree can also estimate the probability that the instance belongs to a particular class $k$. First it traverses the tree to find the leaf node. Then it returns the ratio of training instances of class $k$ for this node. \n",
    "\n",
    "In this case, the number of class 1 for this leaf node is 49 out of 54 so the predicted probability is $\\frac{49}{54}=0.907$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T08:46:23.280529Z",
     "start_time": "2020-04-16T08:46:23.268613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction :  [1]\n",
      "proba :  [[0.         0.90740741 0.09259259]]\n"
     ]
    }
   ],
   "source": [
    "new_s = [[5,1.5]]\n",
    "print('prediction : ', tree_clf.predict(new_s))\n",
    "print('proba : ' , tree_clf.predict_proba(new_s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
