{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 6 -  Decision Trees\n",
    "\n",
    "### Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides classification tasks, decision trees are also capable of performing regression tasks. The following is an example of a regression tree built using the housing dataset.\n",
    "\n",
    "<img src=\"tree2.png\" height=\"300\" />\n",
    "\n",
    "Like the classification tree, the concepts of splitting rules and parts of a tree remain. However, this time the prediction is a value, which is the mean value of all observations within that node $R_m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Tree\n",
    "When training a regression tree, the prediction is a value instead of a class / probability. Given $n$ training examples, each with $p$ features $x_1, \\cdots,x_i,\\cdots, x_n \\in \\mathbb R^p$ and their associated values $y_1, \\cdots, y_j, \\cdots, y_n$, the training steps remain the same. \n",
    "\n",
    "In the Housing example, we have now obtained 8 regions, from left $R_1, R_2, \\cdots, R_8$. The response in each of the nodes are the mean value of prices for all observations in the node. So for a new observation $x^*$, if $x^* \\in R_3$ then its value prediction is $90983.3$.\n",
    "\n",
    "To construct the regions $R_m$, we now find regions that minimise the mean squared error or MSE, where:\n",
    "\n",
    "$$\\text{MSE}_{R_m} = \\frac{1}{n_{R_m}}\\sum_{i \\in R_m}(\\hat{y}-y^{(i)})^2$$\n",
    "\n",
    "<b>Interpretation</b> - A low MSE means that the predicted values are close to the actual values for each observation.\n",
    "\n",
    "During training, the CART algorithm is now:\n",
    "\n",
    "$$J(g,t_g) = \\frac{m_{\\text{left}}}{m}\\text{MSE}_\\text{left} + \\frac{m_{\\text{right}}}{m}\\text{MSE}_\\text{right}$$\n",
    "\n",
    "where $\\text{MSE}_{\\text{left or right}}$ is the MSE of the left or right subset. The split with the lowest MSE for both subsets also miminimse the cost function $J$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T04:09:56.359788Z",
     "start_time": "2020-04-27T04:09:55.115971Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from graphviz import Source # For creating the visualisation of the decision tree\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T04:09:56.435035Z",
     "start_time": "2020-04-27T04:09:56.361996Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ingest, preprocessing\n",
    "X = pd.read_csv('housing_X_feateng_complete.csv')\n",
    "y = pd.read_csv('housing_y_feateng_complete.csv')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T04:09:56.487928Z",
     "start_time": "2020-04-27T04:09:56.437619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=3,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "tree_reg = DecisionTreeRegressor(max_depth=3)\n",
    "tree_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T04:09:56.493854Z",
     "start_time": "2020-04-27T04:09:56.490682Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualise tree\n",
    "# graph = Source(export_graphviz(tree_reg, out_file=None, \n",
    "#                                feature_names=X.columns,))\n",
    "# graph.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T04:09:56.505905Z",
     "start_time": "2020-04-27T04:09:56.496938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183621.088      257344.33890049]\n",
      "[136900.0, 241300.0]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "print(tree_reg.predict(X_test[:2]))\n",
    "print(y_test[:2]['median_house_value'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularisation\n",
    "\n",
    "If left unconstrained the tree usually overfits the training data, leading to poor test set performance. There are some ways to regularise the model. In SKLearn, you can restrict the:\n",
    "- `max_depth` maximum number of traversals from root to leaf\n",
    "\n",
    "- `min_samples_split` minimum number of samples a node must have before a split occurs\n",
    "\n",
    "- `min_samples_leaf` minimum number of samples a leaf node must have\n",
    "\n",
    "- `max_leaf_nodes` maximum number of leaf nodes\n",
    "\n",
    "- `max_features` maximum number of features evaluated for splitting each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Pruning\n",
    "\n",
    "To overcome overfitting, one might consider fitting a smaller tree (with a lower depth). This can lead to lower variance and better interpretation at the cost of some bias. Another alternative is to split results in a high reduction in RSS. By controlling the `max_depth`, we grow a large tree, and then <u>prune</u> it to get a smaller <u>subtree</u>. \n",
    "\n",
    "We can estimate the performace of this subtree using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T04:10:27.700289Z",
     "start_time": "2020-04-27T04:09:56.508780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
       "                                             max_depth=None, max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort='deprecated',\n",
       "                                             random_state=None,\n",
       "                                             splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'max_depth': [1, 2, 3, 4, 5, 6],\n",
       "                          'max_features': [2, 4, 6, 8],\n",
       "                          'max_leaf_nodes': [4, 5, 6, 78, 9, 10, 11, 12, 13, 14,\n",
       "                                             15, 16]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best tree Cross Validation Example\n",
    "tree_param_grid = [{'max_depth' : [1,2,3,4,5,6], \n",
    "                    'max_features' : [2,4,6,8], \n",
    "                    'max_leaf_nodes':[4,5,6,78,9,10,11,12,13,14,15,16]}]\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "grid_search = GridSearchCV(tree_reg, tree_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T04:10:27.708021Z",
     "start_time": "2020-04-27T04:10:27.702919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=6,\n",
      "                      max_features=8, max_leaf_nodes=78,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
