{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3 -  Classification\n",
    "## Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T06:30:39.654130Z",
     "start_time": "2020-04-13T06:30:38.302466Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import (train_test_split, \n",
    "                                     cross_val_score, \n",
    "                                     cross_val_predict)\n",
    "from sklearn.metrics import (confusion_matrix, \n",
    "                             precision_score, recall_score, f1_score,\n",
    "                             classification_report,                              \n",
    "                             precision_recall_curve, roc_auc_score)\n",
    "\n",
    "def load(fname):\n",
    "    mnist = None\n",
    "    try:\n",
    "        with open(fname, 'rb') as f:\n",
    "            mnist = pickle.load(f)\n",
    "            return mnist\n",
    "    except FileNotFoundError:\n",
    "        from sklearn.datasets import fetch_openml\n",
    "        mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "        with open(fname, 'wb') as f:\n",
    "            mnist = pickle.dump(mnist, f)\n",
    "        return mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest, Labelling, Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T06:30:42.329278Z",
     "start_time": "2020-04-13T06:30:39.661015Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_data = load('mnist.data.pkl')\n",
    "X, y = mnist_data['data'], mnist_data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)\n",
    "\n",
    "# Binary Classification - Classify \"5\" or \"not 5\"\n",
    "y_train_5 = (y_train == '5')\n",
    "y_test_5 = (y_test == '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T06:30:42.336323Z",
     "start_time": "2020-04-13T06:30:42.332115Z"
    }
   },
   "outputs": [],
   "source": [
    "# # For testing. Note that 28*28 = 784\n",
    "# print(X.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T06:30:42.346829Z",
     "start_time": "2020-04-13T06:30:42.342897Z"
    }
   },
   "outputs": [],
   "source": [
    "# # For testing\n",
    "# sample_idk = 4\n",
    "# d_single_sample = X[sample_idk]\n",
    "# print(d_single_sample)\n",
    "# d_single_sample_img = d_single_sample.reshape(28, 28)\n",
    "# print(d_single_sample)\n",
    "# plt.imshow(d_single_sample_img, cmap=matplotlib.cm.binary, interpolation='nearest')\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "# print(y[sample_idk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T06:30:42.358758Z",
     "start_time": "2020-04-13T06:30:42.350825Z"
    }
   },
   "outputs": [],
   "source": [
    "kfold = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T06:31:14.527000Z",
     "start_time": "2020-04-13T06:30:42.363472Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9325905  0.96470529 0.96435234] 0.9538827107934393 0.015056555299559625\n"
     ]
    }
   ],
   "source": [
    "# Create model, train\n",
    "sgd_clf = SGDClassifier(random_state=0)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n",
    "# Cross-Validation gives the output when the sample is in the test set.\n",
    "cvs1 = cross_val_score(estimator=sgd_clf, X=X_train, y=y_train_5, cv=kfold)\n",
    "print(cvs1, cvs1.mean(), cvs1.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows that the estimator gives a 94% accuracy, very good! Now compare this with the dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T06:31:15.274630Z",
     "start_time": "2020-04-13T06:31:14.530462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90813754 0.91105733 0.90909091] 0.9094285931269165 0.001215678701391952\n"
     ]
    }
   ],
   "source": [
    "class Dummy5Classifier(BaseEstimator):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "    \n",
    "dummy_clf = Dummy5Classifier()\n",
    "dummy_clf.fit(X_train, y_train_5)\n",
    "\n",
    "cvs2 = cross_val_score(estimator=dummy_clf, X=X_train, y=y_train_5, cv=kfold, scoring='accuracy')\n",
    "print(cvs2, cvs2.mean(), cvs2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy classifier gave a 91% accuracy, which makes sense. If 91% of the images are not 5, then, by using rules, predicting \"not 5\" alone gives already a high accuracy. Hence, accuracy is generally not preferred as a performance measures when the classifier has skewed datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T06:31:35.980094Z",
     "start_time": "2020-04-13T06:31:15.279983Z"
    }
   },
   "outputs": [],
   "source": [
    "# cross_val_predict gives the prediction result of each sample when it\n",
    "# is in the test set group\n",
    "sgd_ypred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is $\\frac{TP}{TP+FP}$, of all you predicted class 1, how many were predicted wrongly?\n",
    "\n",
    "Recall is $\\frac{TP}{TP+FN}$, of all samples that are class 1, how many were predicted wrongly?\n",
    "\n",
    "F1 score is harmonic mean of Precision & Recall. $$F_1 = \\frac{2}{\\frac{1}{precision} + \\frac{1}{recall}}$$A harmonic mean gives more weight to low values. Hence, the classifier will only get a high F1 score if both precision & recall are high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T06:31:36.104140Z",
     "start_time": "2020-04-13T06:31:35.982553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52467  1644]\n",
      " [ 1100  4289]]\n",
      "0.7229057812236642\n",
      "0.7958804973093339\n",
      "0.7576399929341107\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train_5, sgd_ypred)) # first value takes row, 2nd value takes columns\n",
    "print(precision_score(y_train_5, sgd_ypred)) \n",
    "print(recall_score(y_train_5, sgd_ypred))\n",
    "print(f1_score(y_train_5, sgd_ypred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
